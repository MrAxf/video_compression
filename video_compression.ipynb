{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of redundancy\n",
    "1. **Spatial redundancy**: Pixels are very similar in its neighborhood or tends to repeat textures.\n",
    "2. **Temporal redundancy**: Temporally adjacent images are typically very alike.\n",
    "3. **Visual redundancy**: Humans hardly perceive high spatial and temporal frequencies (we like more low frequencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block-based MC (Motion Compensation)\n",
    "\n",
    "* Usually, only performed by the encoder.\n",
    "* MC removes temporal redundancy. A *predicted image* can be\n",
    "  encoded as the difference between it and another image called\n",
    "  *prediction image* which is a motion compensated projection of\n",
    "  one or more images named *reference images*. ME tries to\n",
    "  generate *residue images* as close as possible to the null\n",
    "  images.\n",
    "* Usually, the reference image/s is/are divided in blocks of\n",
    "  $16\\times 16$ pixels called *macroblocks*.\n",
    "* Each reference block is searched in the predicted image and the\n",
    "  best match is indicated by mean of a *motion vector*.\n",
    "* Depending on the success of the search and the number of\n",
    "  reference images, the macroblocks are classified into:\n",
    "  + **I (intra)**: When the compression of residue block generates more\n",
    "    bits than the original (predicted) one.\n",
    "  + **P (predicted)**: When it is better to compress the residue block and\n",
    "    there is only one reference macroblock.\n",
    "  + **B (bidirectionally predicted)**: The same, but if we have two reference macroblocks.\n",
    "  + **S (skipped)**: When the energy of the residue block is\n",
    "    smaller than a given threshold.\n",
    "* I-pictures are composed of I macroblocks, only.\n",
    "* P-pictures do not have B macrobocks.\n",
    "* B-pictures can have any type of macroblocks.\n",
    "\n",
    "<img src=\"figs/macroblocks.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-pixel accuracy\n",
    "\n",
    "* The motion estimation can be carried out using integer pixel\n",
    "  accuracy or a fractional (sub-) pixel accuracy.\n",
    "* For example, in MPEG-1, the motion estimation can have up to 1/2\n",
    "  pixel accuracy. A bi-linear interpolator is used:\n",
    "\n",
    "<img src=\"figs/interpolation.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching criteria (similitude between macroblocks)\n",
    "\n",
    "* Let $a$ and $b$ the macroblocks which we want to compare. Two\n",
    "  main distortion metrics are commonly used:\n",
    "  \n",
    "  + **Mean Square Error**:\n",
    "  \n",
    "    \\begin{equation}\n",
    "      \\frac{1}{16\\times 16}\\sum_{i=1}^{16}\\sum_{j=1}^{16}(a_{ij}-b_{ij})^2\n",
    "    \\end{equation}\n",
    "    \n",
    "  + **Mean Absolute Error**:\n",
    "  \n",
    "    \\begin{equation}\n",
    "      \\frac{1}{16\\times 16}\\sum_{i=1}^{16}\\sum_{j=1}^{16}|a_{ij}-b_{ij}|\n",
    "    \\end{equation}\n",
    "\n",
    "* These similitude measures are used only by the\n",
    "  compressor. Therefore, any other one with similar effects (such as\n",
    "  the error variance or the error entropy) could be used also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching strategies\n",
    "\n",
    "* Only performed by the compressor.\n",
    "\n",
    "    + **Full search**: All the possibilities are\n",
    "    checked. Advantage: the best compression. Disadvantage: CPU\n",
    "    killer.\n",
    "    \n",
    "    <img src=\"figs/full_search.svg\">\n",
    "\n",
    "    + ** Logaritmic search**: It is a version of the full search\n",
    "    algorithm where the macro-blocks and the search area are\n",
    "    sub-sampled. After finding the best coincidence, the resolution of\n",
    "    the macro-block is increased in a power of 2 and the previous\n",
    "    match is refined in a search area of $\\pm 1$, until the maximal\n",
    "    resolution (even using subpixel accuracy) is reached.\n",
    "    \n",
    "    + **Telescopic search**: Any of the previously described\n",
    "    techniques can be speeded up if the searching area is\n",
    "    reduced. This can be done supposing that the motion vector of the\n",
    "    same macro-block in two consecutive images is similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GOP (Group Of Pictures) concept\n",
    "\n",
    "* The temporal redundancy is exploited by blocks of images called\n",
    "  GOPs. This means that a GOP can be decoded independently of the rest\n",
    "  of GOPs. Here an example:\n",
    "  \n",
    "<img src=\"figs/GOPs.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTF (Motion Compensated Temporal Filtering)\n",
    "\n",
    "* This is a DWT where the input samples are the original video\n",
    "  images and the output is a sequence of residue images.\n",
    "  \n",
    "<img src=\"figs/MCTF.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t+2d vs. 2d+t vs. 2d+t+2d\n",
    "\n",
    "* **t+2d**: The sequence of images is decorrelated first\n",
    "  along the time (t) and the residue images are compressed, exploiting\n",
    "  the remaining spatial (2d) redundancy. Examples: MPEG* and H.26*\n",
    "  codecs (except H.264/SVC).\n",
    "  \n",
    "* **2d+t**: The spatial (2d) redudancy is explited first\n",
    "  (using typically the DWT) and next the coefficients are decorrelated\n",
    "  along the time (t). To date this has only been experimental setup\n",
    "  because most transformed domains are not invariant to the\n",
    "  displacement.\n",
    "  \n",
    "* **2d+t+2d**: The fist step creates a Laplacian Pyramid\n",
    "  (2d), which is invariant to the displacement. Next, each level of\n",
    "  the pyramid is decorrelated along the time (t) and finally, the\n",
    "  remaining spatial redundancy is removed (2d). Example: H.264/SVC.\n",
    "\n",
    "<img src=\"figs/H264-S-SVC.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deblocking filtering\n",
    "\n",
    "* Block based video encoders (those than use block-based temporal\n",
    "  decorrelation) improve their performance if a deblocking filter in\n",
    "  used to create the quantized prediction predictions.\n",
    "  \n",
    "<img src=\"figs/350px-Deblock1.jpg\" width=600>\n",
    "\n",
    "* The low-pass filter is applied only on the block boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit-rate allocation\n",
    "\n",
    "* Under a constant quantization level (constant video quality),\n",
    "  the number of bits that each compressed image needs depends on the\n",
    "  image content. Example:\n",
    "\n",
    "  <img src=\"figs/closed-loop-1_ir.svg\">\n",
    "\n",
    "* The encoder must decide how much information will be stored in\n",
    "  each residue image, taking into account that this image can serve as\n",
    "  a reference for other images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality scalability\n",
    "\n",
    "<img src=\"figs/quality-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* Ideal for remote visualization environments.\n",
    "\n",
    "* In reversible codecs, $V_i^{[0]}=V_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal scalability\n",
    "\n",
    "<img src=\"00-fundamentals/temporal-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* It holds that:\n",
    "\\begin{equation}\n",
    "  V^{t}=\\{V_{2^t\\times i};~0\\le i < \\frac{\\text{#}V}{2^t}\\}=\\{V_{2i}^{t-1};~0\\le i < \\frac{\\text{#}V^{t-1}}{2}\\},\n",
    "\\end{equation}\n",
    "where $\\text{#}V$ is the number of pixtures in $V$ and $t$ denotes the\n",
    "Temporal Resolution Level (TRL).\n",
    "\n",
    "* Notice that $V=V^{0}$.\n",
    "\n",
    "* Useful for fast random access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial scalability\n",
    "\n",
    "<img src=\"00-fundamentals/spatial-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* Useful for low-resolution devices.\n",
    "\n",
    "* In reversible codecs, $V_i=V_i^{<0>}$ and $V_i^{<s>}$ has a\n",
    "  $\\frac{Y}{2^s}\\times \\frac{X}{2^s}$ resolution, where $X\\times Y$ is\n",
    "  the resolution of $V_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Media encoding models\n",
    "\n",
    "<img src=\"00-fundamentals/media-encoding-models.svg\" style=\"width: 400px;\"/>\n",
    "\n",
    "### 1. Single Layer Coding (SLC)\n",
    "\n",
    "* Most audio and image/video codecs generate non-scalable\n",
    "  streams. In the case of video, only one quality, resolution and\n",
    "  picture-rate are available at decoding time.\n",
    "  \n",
    "* The decoding of a single layered stream generates a\n",
    "  reconstruction whose quality is linearly proportional to the amount\n",
    "  of decoded data.\n",
    "  \n",
    "### 2. [Multiple Layer Coding (MLC)](http://eeweb.poly.edu/~yao/EL6123/scalablecoding.pdf)\n",
    "\n",
    "* A media encoded in several layers can be decoded to provide (in\n",
    "  the case of video) different picture-rates (time scalability),\n",
    "  different resolutions (spatial scalability) and different qualities\n",
    "  (quality scalability).\n",
    "  \n",
    "* In some codecs (such as JPEG 2000), spatial random access it is\n",
    "  available ROI (Region-Of-Interest) or WOI (Window-Of-Interest)\n",
    "  scalability. ROI is used in special imaging, such as [mammography](http://en.wikipedia.org/wiki/Mammography). WOI can\n",
    "  useful in the retrieving of high-resolution video sequences such as [JHelioviewer](http://jhelioviewer.org/linux.html).\n",
    "  \n",
    "### 3. [Multiple Description Coding (MDC)](http://en.wikipedia.org/wiki/Multiple_description_coding)\n",
    "\n",
    "* Multiple description codecs provides a set of\n",
    "  partially redundant streams so that the quality of the reconstructions\n",
    "  improve with the number of descriptions decoded.\n",
    "  \n",
    "* An example of this type of encoding is the scene segmentation\n",
    "  (video object coding) provided by [MPEG-4](http://www.cs.cf.ac.uk/Dave/MM/BSC_MM_CALLER/PDF/12_CM340_MPEG4_VIDEO.pdf).\n",
    "  \n",
    "### 4. [Media simulcast](http://en.wikipedia.org/wiki/Simulcast)\n",
    "\n",
    "* In transmission scenarios, a source can store several copies of\n",
    "  the same media, althought variying the temporal resolution, spatial\n",
    "  resolution and/or quality.\n",
    "  \n",
    "* Obviously, this is quite redundant at the source side. However,\n",
    "  as it will be shown after, adaptive services can be provided with\n",
    "  this technique, such as in YouTube."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
